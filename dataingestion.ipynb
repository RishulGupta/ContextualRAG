{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "4f42efa8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 1: Input text and chunking\n",
    "input_text = \"\"\"Berlin is the capital and largest city of Germany, both by area and by population.\n",
    "Its more than 3.85 million inhabitants make it the European Union's most populous city, as measured by population within city limits.\n",
    "The city is also one of the states of Germany and is the third smallest state in the country in terms of area.\n",
    "Paris is the capital and most populous city of France.\n",
    "It is situated along the Seine River in the north-central part of the country.\n",
    "The city has a population of over 2.1 million residents within its administrative limits, making it one of Europe's major population centers.\"\"\"\n",
    "\n",
    "# Split into sentence-level chunks\n",
    "test_chunks = [sentence.strip() for sentence in input_text.split('\\n') if sentence.strip()]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "da5bde15",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.prompts import ChatPromptTemplate, PromptTemplate, HumanMessagePromptTemplate\n",
    "\n",
    "# Anthropic-style system prompt template\n",
    "anthropic_contextual_retrieval_system_prompt = \"\"\"<document>\n",
    "{WHOLE_DOCUMENT}\n",
    "</document>\n",
    "Here is the chunk we want to situate within the whole document\n",
    "<chunk>\n",
    "{CHUNK_CONTENT}\n",
    "</chunk>\n",
    "Please give a short succinct context to situate this chunk within the overall document for the purposes of improving search retrieval of the chunk. Answer only with the succinct context and nothing else.\"\"\"\n",
    "\n",
    "# Create a basic prompt template\n",
    "anthropic_prompt_template = PromptTemplate(\n",
    "    input_variables=[\"WHOLE_DOCUMENT\", \"CHUNK_CONTENT\"],\n",
    "    template=anthropic_contextual_retrieval_system_prompt\n",
    ")\n",
    "\n",
    "# Wrap the prompt in HumanMessagePromptTemplate\n",
    "human_message_prompt = HumanMessagePromptTemplate(prompt=anthropic_prompt_template)\n",
    "\n",
    "# Final ChatPromptTemplate used for the model\n",
    "anthropic_contextual_retrieval_final_prompt = ChatPromptTemplate(\n",
    "    input_variables=[\"WHOLE_DOCUMENT\", \"CHUNK_CONTENT\"],\n",
    "    messages=[human_message_prompt]\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "dd377b34",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ChatGroq(client=<groq.resources.chat.completions.Completions object at 0x7fe1af889b20>, async_client=<groq.resources.chat.completions.AsyncCompletions object at 0x7fe1af877f80>, model_name='Gemma2-9b-It', model_kwargs={}, groq_api_key=SecretStr('**********'))"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import os\n",
    "groq_api_key=os.getenv(\"GROQ_API_KEY\")\n",
    "from langchain_groq import ChatGroq\n",
    "llm=ChatGroq(groq_api_key=groq_api_key,model=\"Gemma2-9b-It\")\n",
    "llm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "5e1bcc43",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_core.output_parsers import StrOutputParser\n",
    "\n",
    "# Connect prompt, model, and parser into a chain\n",
    "contextual_chunk_creation = anthropic_contextual_retrieval_final_prompt | llm | StrOutputParser()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "1949b418",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Chunk: Berlin is the capital and largest city of Germany, both by area and by population.\n",
      "Context: Describing the population and size of Berlin.  \n",
      "\n",
      "----------------------------------------\n",
      "Chunk: Its more than 3.85 million inhabitants make it the European Union's most populous city, as measured by population within city limits.\n",
      "Context: Describing Berlin's population and ranking within the EU.  \n",
      "\n",
      "----------------------------------------\n",
      "Chunk: The city is also one of the states of Germany and is the third smallest state in the country in terms of area.\n",
      "Context: This sentence describes Berlin's status as a state within Germany.  \n",
      "\n",
      "----------------------------------------\n",
      "Chunk: Paris is the capital and most populous city of France.\n",
      "Context: This chunk describes Paris as the capital and most populous city of France.  \n",
      "\n",
      "----------------------------------------\n",
      "Chunk: It is situated along the Seine River in the north-central part of the country.\n",
      "Context: Describing the geographic location of Paris. \n",
      "\n",
      "----------------------------------------\n",
      "Chunk: The city has a population of over 2.1 million residents within its administrative limits, making it one of Europe's major population centers.\n",
      "Context: Describing Paris's population and significance. \n",
      "\n",
      "----------------------------------------\n"
     ]
    }
   ],
   "source": [
    "contextual_chunks = []\n",
    "\n",
    "for chunk in test_chunks:\n",
    "    context = contextual_chunk_creation.invoke({\n",
    "        \"WHOLE_DOCUMENT\": input_text,\n",
    "        \"CHUNK_CONTENT\": chunk\n",
    "    })\n",
    "    contextual_chunks.append({\n",
    "        \"chunk\": chunk,\n",
    "        \"context\": context\n",
    "    })\n",
    "\n",
    "# Optional: Print to verify\n",
    "for entry in contextual_chunks:\n",
    "    print(f\"Chunk: {entry['chunk']}\\nContext: {entry['context']}\\n{'-'*40}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1d7e5861",
   "metadata": {},
   "source": [
    "reranker simple\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "dfb3e83b",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/rishulgupta/contextualretrieverragprototype/venv/lib/python3.12/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Score: 0.7287\n",
      "Chunk: Berlin is the capital and largest city of Germany, both by area and by population.\n",
      "Context: Describing the population and size of Berlin.  \n",
      "\n",
      "==================================================\n",
      "Score: 0.5577\n",
      "Chunk: Its more than 3.85 million inhabitants make it the European Union's most populous city, as measured by population within city limits.\n",
      "Context: Describing Berlin's population and ranking within the EU.  \n",
      "\n",
      "==================================================\n",
      "Score: 0.5454\n",
      "Chunk: The city has a population of over 2.1 million residents within its administrative limits, making it one of Europe's major population centers.\n",
      "Context: Describing Paris's population and significance. \n",
      "\n",
      "==================================================\n"
     ]
    }
   ],
   "source": [
    "from sentence_transformers import SentenceTransformer, util\n",
    "\n",
    "model = SentenceTransformer(\"all-MiniLM-L6-v2\")\n",
    "query_embedding = model.encode(\"What is the population of Berlin?\", convert_to_tensor=True)\n",
    "\n",
    "# Score and sort by similarity\n",
    "scored_chunks = []\n",
    "for entry in contextual_chunks:\n",
    "    chunk_embedding = model.encode(entry[\"chunk\"], convert_to_tensor=True)\n",
    "    score = util.pytorch_cos_sim(query_embedding, chunk_embedding).item()\n",
    "    scored_chunks.append((entry, score))\n",
    "\n",
    "# Sort by descending score\n",
    "top_chunks = sorted(scored_chunks, key=lambda x: x[1], reverse=True)[:3]\n",
    "\n",
    "# Print top reranked results\n",
    "for (entry, score) in top_chunks:\n",
    "    print(f\"Score: {score:.4f}\\nChunk: {entry['chunk']}\\nContext: {entry['context']}\\n{'='*50}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "aeb248d3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Final Answer: The context provides two figures for Berlin's population:\n",
      "\n",
      "* **Over 3.85 million inhabitants** when considering the entire city area.\n",
      "* **Over 2.1 million residents** within its administrative limits. \n",
      "\n",
      "\n",
      "So, the population of Berlin depends on how you define its boundaries. \n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "final_context = \"\\n\".join([entry[\"chunk\"] for (entry, _) in top_chunks])\n",
    "final_prompt = f\"\"\"Based on the following context, answer the question:\n",
    "\n",
    "Context:\n",
    "{final_context}\n",
    "\n",
    "Question:\n",
    "What is the population of Berlin?\"\"\"\n",
    "\n",
    "response = llm.invoke(final_prompt)\n",
    "print(\"Final Answer:\", response.content)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
